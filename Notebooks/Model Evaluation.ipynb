{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation of Different Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import scipy\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from src.models import classification_transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_transformer = classification_transformer.Main(\"large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>artist</th>\n",
              "      <th>decade</th>\n",
              "      <th>genre</th>\n",
              "      <th>ratings</th>\n",
              "      <th>stars</th>\n",
              "      <th>chords</th>\n",
              "      <th>style_s</th>\n",
              "      <th>style_m</th>\n",
              "      <th>style_l</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://tabs.ultimate-guitar.com/tab/jeff-buck...</td>\n",
              "      <td>Hallelujah</td>\n",
              "      <td>Jeff Buckley</td>\n",
              "      <td>1990</td>\n",
              "      <td>Rock|Folk</td>\n",
              "      <td>51639.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[tensor(685), tensor(677), tensor(685), tensor...</td>\n",
              "      <td>[tensor(-0.3856), tensor(-1.9832), tensor(2.09...</td>\n",
              "      <td>[tensor(1.3062), tensor(-0.7475), tensor(0.239...</td>\n",
              "      <td>[tensor(-1.0692), tensor(0.6523), tensor(1.242...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://tabs.ultimate-guitar.com/tab/ed-sheera...</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>Ed Sheeran</td>\n",
              "      <td>2010</td>\n",
              "      <td>Pop</td>\n",
              "      <td>44194.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[tensor(162), tensor(34), tensor(685), tensor(...</td>\n",
              "      <td>[tensor(-0.4196), tensor(-2.5276), tensor(0.92...</td>\n",
              "      <td>[tensor(1.3084), tensor(-0.2184), tensor(0.411...</td>\n",
              "      <td>[tensor(-1.5094), tensor(1.2023), tensor(2.055...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://tabs.ultimate-guitar.com/tab/elvis-pre...</td>\n",
              "      <td>Cant Help Falling In Love</td>\n",
              "      <td>Elvis Presley</td>\n",
              "      <td>1960</td>\n",
              "      <td>Soundtrack|R&amp;B, Funk &amp; Soul</td>\n",
              "      <td>30059.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[tensor(685), tensor(162), tensor(677), tensor...</td>\n",
              "      <td>[tensor(-1.4292), tensor(-2.7096), tensor(3.19...</td>\n",
              "      <td>[tensor(1.6858), tensor(-0.6888), tensor(-0.22...</td>\n",
              "      <td>[tensor(-2.5916), tensor(0.9577), tensor(0.642...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://tabs.ultimate-guitar.com/tab/eagles/ho...</td>\n",
              "      <td>Hotel California</td>\n",
              "      <td>Eagles</td>\n",
              "      <td>1970</td>\n",
              "      <td>Rock</td>\n",
              "      <td>28670.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[tensor(173), tensor(422), tensor(397), tensor...</td>\n",
              "      <td>[tensor(-1.1563), tensor(-2.2659), tensor(3.00...</td>\n",
              "      <td>[tensor(1.7773), tensor(-0.7144), tensor(-0.03...</td>\n",
              "      <td>[tensor(-2.1881), tensor(0.8039), tensor(-0.08...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://tabs.ultimate-guitar.com/tab/radiohead...</td>\n",
              "      <td>Creep</td>\n",
              "      <td>Radiohead</td>\n",
              "      <td>1990</td>\n",
              "      <td>Rock</td>\n",
              "      <td>28606.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[tensor(162), tensor(83), tensor(685), tensor(...</td>\n",
              "      <td>[tensor(-0.4531), tensor(-3.7440), tensor(1.14...</td>\n",
              "      <td>[tensor(1.9167), tensor(0.1738), tensor(-0.065...</td>\n",
              "      <td>[tensor(-2.5974), tensor(0.5083), tensor(0.480...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  \\\n",
              "0  https://tabs.ultimate-guitar.com/tab/jeff-buck...   \n",
              "1  https://tabs.ultimate-guitar.com/tab/ed-sheera...   \n",
              "2  https://tabs.ultimate-guitar.com/tab/elvis-pre...   \n",
              "3  https://tabs.ultimate-guitar.com/tab/eagles/ho...   \n",
              "4  https://tabs.ultimate-guitar.com/tab/radiohead...   \n",
              "\n",
              "                       title         artist  decade  \\\n",
              "0                 Hallelujah   Jeff Buckley    1990   \n",
              "1                    Perfect     Ed Sheeran    2010   \n",
              "2  Cant Help Falling In Love  Elvis Presley    1960   \n",
              "3           Hotel California         Eagles    1970   \n",
              "4                      Creep      Radiohead    1990   \n",
              "\n",
              "                         genre  ratings  stars  \\\n",
              "0                    Rock|Folk  51639.0    5.0   \n",
              "1                          Pop  44194.0    5.0   \n",
              "2  Soundtrack|R&B, Funk & Soul  30059.0    5.0   \n",
              "3                         Rock  28670.0    5.0   \n",
              "4                         Rock  28606.0    5.0   \n",
              "\n",
              "                                              chords  \\\n",
              "0  [tensor(685), tensor(677), tensor(685), tensor...   \n",
              "1  [tensor(162), tensor(34), tensor(685), tensor(...   \n",
              "2  [tensor(685), tensor(162), tensor(677), tensor...   \n",
              "3  [tensor(173), tensor(422), tensor(397), tensor...   \n",
              "4  [tensor(162), tensor(83), tensor(685), tensor(...   \n",
              "\n",
              "                                             style_s  \\\n",
              "0  [tensor(-0.3856), tensor(-1.9832), tensor(2.09...   \n",
              "1  [tensor(-0.4196), tensor(-2.5276), tensor(0.92...   \n",
              "2  [tensor(-1.4292), tensor(-2.7096), tensor(3.19...   \n",
              "3  [tensor(-1.1563), tensor(-2.2659), tensor(3.00...   \n",
              "4  [tensor(-0.4531), tensor(-3.7440), tensor(1.14...   \n",
              "\n",
              "                                             style_m  \\\n",
              "0  [tensor(1.3062), tensor(-0.7475), tensor(0.239...   \n",
              "1  [tensor(1.3084), tensor(-0.2184), tensor(0.411...   \n",
              "2  [tensor(1.6858), tensor(-0.6888), tensor(-0.22...   \n",
              "3  [tensor(1.7773), tensor(-0.7144), tensor(-0.03...   \n",
              "4  [tensor(1.9167), tensor(0.1738), tensor(-0.065...   \n",
              "\n",
              "                                             style_l  \n",
              "0  [tensor(-1.0692), tensor(0.6523), tensor(1.242...  \n",
              "1  [tensor(-1.5094), tensor(1.2023), tensor(2.055...  \n",
              "2  [tensor(-2.5916), tensor(0.9577), tensor(0.642...  \n",
              "3  [tensor(-2.1881), tensor(0.8039), tensor(-0.08...  \n",
              "4  [tensor(-2.5974), tensor(0.5083), tensor(0.480...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('../Data/data_styled.csv')\n",
        "for col in [\"chords\", \"style_s\", \"style_m\", \"style_l\"]:\n",
        "    data[col] = data[col].apply(lambda x: torch.tensor(json.loads(x)))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into train and test sets as in the previous notebooks\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class ChordDataset: # A dummy dataset class\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "dataset = ChordDataset(data)\n",
        "train_size = int(np.rint(len(dataset) * 0.8))\n",
        "train_indices, test_indices = random_split(range(len(dataset)), [train_size, len(dataset) - train_size])\n",
        "\n",
        "# Convert the indices to lists\n",
        "train_indices = [idx for idx in train_indices.indices]\n",
        "test_indices = [idx for idx in test_indices.indices]\n",
        "\n",
        "# Split the dataframe using the indices\n",
        "train_data = data.iloc[train_indices]\n",
        "test_data = data.iloc[test_indices]\n",
        "\n",
        "# Reindex the dataframes\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "test_data = test_data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 17790, Test size: 4448\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train size: {len(train_data)}, Test size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fr√©chet Feature Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Evaluation:\n",
        "    def __init__(self, ref_column):\n",
        "        self.ref_column = ref_column        \n",
        "        self.augmentation_map = torch.tensor(np.load('../Data/augmentation_map.npy', allow_pickle=True))\n",
        "        self.augmentation_map = self.augmentation_map.to(embedding_transformer.device)\n",
        "\n",
        "    \n",
        "    def augment(self, chords):\n",
        "        \"\"\"Change the root note of the chords by a random amount\"\"\"\n",
        "        move_by = torch.randint(0, 12, [1]).item()\n",
        "        return self.augmentation_map[chords, move_by]\n",
        "        \n",
        "    def pad(self, chords):\n",
        "        \"\"\"Pad the input 2D tensor [n] into shape [256] with zeros\"\"\"\n",
        "        out = torch.zeros((256), dtype=torch.long, device=embedding_transformer.device)\n",
        "        out[:len(chords)] = chords\n",
        "        return out\n",
        "    \n",
        "    def reduce_dimensionality(self, column, batch_size=64, augment=False):\n",
        "        \"\"\"Use a pretrained classifier to reduce the dimensionality of the dataframes.\"\"\"\n",
        "        \n",
        "        reduced_column = []\n",
        "        n = len(column)\n",
        "        \n",
        "        for i in range(0, n, batch_size):\n",
        "            # Extract the current batch of data\n",
        "            batch = column[i:i+batch_size]\n",
        "            \n",
        "            # Convert batch to torch tensor and process it\n",
        "            batch_tensor = [torch.tensor(item.tolist(), dtype=torch.long, device=embedding_transformer.device) for item in batch]\n",
        "            if augment:\n",
        "                batch_tensor = torch.stack([self.pad(self.augment(item)) for item in batch_tensor])\n",
        "            else:\n",
        "                batch_tensor = torch.stack([self.pad(item) for item in batch_tensor])\n",
        "            \n",
        "            # Get embeddings for the entire batch and append to reduced_column\n",
        "            batch_embeddings = embedding_transformer.batch_extract_features(batch_tensor)\n",
        "            reduced_column.extend(batch_embeddings)\n",
        "            \n",
        "        return reduced_column\n",
        "    \n",
        "    def frechet_distance(self, mu1, mu2, sigma1, sigma2):\n",
        "        \"\"\"\n",
        "        Compute the Frechet distance between two multivariate Gaussians.\n",
        "        \n",
        "        Args:\n",
        "            mu1, mu2: mean vectors (1D numpy arrays)\n",
        "            sigma1, sigma2: covariance matrices (2D numpy arrays)\n",
        "            \n",
        "        Returns:\n",
        "            The Frechet distance between the two distributions.\n",
        "        \"\"\"\n",
        "        mu_diff = mu1 - mu2\n",
        "        # The following line computes (sigma1 * sigma2)^(1/2) using the matrix square root\n",
        "        sqrt_sigma = scipy.linalg.sqrtm(np.dot(sigma1, sigma2))\n",
        "        \n",
        "        # Handling numerical instability (may occur if matrices are nearly singular)\n",
        "        if not np.isfinite(sqrt_sigma).all():\n",
        "            offset = np.eye(sigma1.shape[0]) * 1e-10\n",
        "            sqrt_sigma = scipy.linalg.sqrtm(np.dot(sigma1 + offset, sigma2 + offset))\n",
        "        \n",
        "        # Compute the trace term\n",
        "        tr_term = np.trace(sigma1 + sigma2 - 2 * sqrt_sigma)\n",
        "        \n",
        "        # Compute the difference term\n",
        "        diff_term = np.dot(mu_diff, mu_diff)\n",
        "        \n",
        "        return diff_term + tr_term\n",
        "    \n",
        "    def calculate_frechet_distance(self, ref_column, gen_column):\n",
        "        \"\"\"Calculate the Frechet distance between the reference and generated samples for the reduced columns.\"\"\"\n",
        "        ref_column, gen_column = np.array(ref_column), np.array(gen_column)\n",
        "        mu1 = np.mean(ref_column, axis=0)\n",
        "        mu2 = np.mean(gen_column, axis=0)\n",
        "\n",
        "        sigma1 = np.cov(ref_column, rowvar=False)\n",
        "        sigma2 = np.cov(gen_column, rowvar=False)\n",
        "\n",
        "        # Compute the Frechet distance\n",
        "        return self.frechet_distance(mu1, mu2, sigma1, sigma2)\n",
        "    \n",
        "    def preprocess_ref_col(self):\n",
        "        \"\"\"Reduce the dimensionality of the reference column.\"\"\"\n",
        "        self.ref_reduced_column = self.reduce_dimensionality(self.ref_column, augment=True)\n",
        "    \n",
        "    def get_column_score(self, gen_column):\n",
        "        \"\"\"Get the score for a generated column.\"\"\"\n",
        "        gen_reduced_column = self.reduce_dimensionality(gen_column)\n",
        "        distances = self.calculate_frechet_distance(self.ref_reduced_column, gen_reduced_column)\n",
        "        return distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "eval = Evaluation(test_data[\"chords\"])\n",
        "eval.preprocess_ref_col()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(file_name):\n",
        "    gen_df = pd.read_csv(f\"../Data/Generated/{file_name}.csv\")\n",
        "    gen_df[\"chords\"] = gen_df[\"chords\"].apply(lambda x: torch.tensor(json.loads(x), dtype=torch.long))\n",
        "    score = eval.get_column_score(gen_df[\"chords\"])\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>recurrent_net</td>\n",
              "      <td>9.290163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>transformer_small</td>\n",
              "      <td>3.201061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>transformer_medium</td>\n",
              "      <td>2.814373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>transformer_large</td>\n",
              "      <td>2.315624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>conditional_small</td>\n",
              "      <td>2.998407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>conditional_medium</td>\n",
              "      <td>2.075891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>conditional_large</td>\n",
              "      <td>1.848373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>style_small</td>\n",
              "      <td>1.727796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>style_medium</td>\n",
              "      <td>1.138680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>style_large</td>\n",
              "      <td>0.823672</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                model     score\n",
              "0       recurrent_net  9.290163\n",
              "1   transformer_small  3.201061\n",
              "2  transformer_medium  2.814373\n",
              "3   transformer_large  2.315624\n",
              "4   conditional_small  2.998407\n",
              "5  conditional_medium  2.075891\n",
              "6   conditional_large  1.848373\n",
              "7         style_small  1.727796\n",
              "8        style_medium  1.138680\n",
              "9         style_large  0.823672"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = []\n",
        "sizes = [\"small\", \"medium\", \"large\"]\n",
        "files = [\"recurrent_net\"] + [f\"transformer_{s}\" for s in sizes] + [f\"conditional_{s}\" for s in sizes] + [f\"style_{s}\" for s in sizes]\n",
        "for file_name in files:\n",
        "    scores.append({\"model\": file_name, \"score\": evaluate(file_name)})\n",
        "scores = pd.DataFrame(scores)\n",
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Top-1 accuracy & Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from src.models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 1035\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, model, device):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "\n",
        "    def loss_mask(self, y_pred, x):\n",
        "        \"\"\"Get the mask for the loss function, so that the loss is not calculated for the padded elements\"\"\"\n",
        "        eos_index = torch.argmax((x == VOCAB_SIZE - 1).float(), dim=1)\n",
        "        range_tensor = torch.arange(y_pred.shape[1]).unsqueeze(0).expand(y_pred.shape[0], -1).to(self.device)\n",
        "        mask = range_tensor <= eos_index.unsqueeze(1)\n",
        "        return mask\n",
        "    \n",
        "    def masked_accuracy(self, y_pred, x):\n",
        "        \"\"\"Calculate the accuracy of the model only for the elements of the sequence\"\"\"\n",
        "        y_pred, x = y_pred[:, :-1], x[:, 1:]\n",
        "        eos_index = torch.argmax((x == VOCAB_SIZE - 1).float(), dim=1)\n",
        "        range_tensor = torch.arange(y_pred.shape[1]).unsqueeze(0).expand(y_pred.shape[0], -1).to(self.device)\n",
        "        # EOS is not included in the accuracy calculation\n",
        "        mask = range_tensor < eos_index.unsqueeze(1)\n",
        "        valid_elements = torch.sum(mask.float())\n",
        "\n",
        "        same = torch.argmax(y_pred, dim=2) == x\n",
        "            \n",
        "        return torch.sum(same.float() * mask.float()) / valid_elements\n",
        "    \n",
        "    def masked_cross_entropy(self, logits, target, mask):\n",
        "        \"\"\"\n",
        "        logits: Predictions from the model, of shape (batch_size, sequence_length, vocab_size)\n",
        "        target: Ground truth labels, of shape (batch_size, sequence_length)\n",
        "        mask: Binary mask indicating the non-padded parts, of shape (batch_size, sequence_length)\n",
        "        \"\"\"\n",
        "\n",
        "        # Compute the raw CrossEntropyLoss\n",
        "        loss = nn.CrossEntropyLoss(reduction='none')(logits.transpose(1, 2), target)\n",
        "\n",
        "        # Apply the mask to the loss\n",
        "        masked_loss = loss * mask.float()\n",
        "\n",
        "        # Compute the mean loss over non-padded parts\n",
        "        final_loss = masked_loss.sum() / mask.float().sum()\n",
        "\n",
        "        return final_loss\n",
        "                   \n",
        "        \n",
        "    def eval_step(self, data_loader, model_name):\n",
        "        self.model.eval()\n",
        "        \n",
        "        average_loss = 0\n",
        "        average_accuracy = 0\n",
        "        for i, x in enumerate(data_loader):\n",
        "            if \"conditional\" in model_name:\n",
        "                x, style, _ = x\n",
        "                x, style = x.to(self.device), style.to(self.device)\n",
        "                with torch.inference_mode():\n",
        "                    y_pred = self.model(x, style)\n",
        "            elif \"style\" in model_name:\n",
        "                x, _, styles = x\n",
        "                style = styles[[\"small\", \"medium\", \"large\"].index(model_name.split(\"_\")[-1])]\n",
        "                x, style = x.to(self.device), style.to(self.device)\n",
        "                with torch.inference_mode():\n",
        "                    y_pred = self.model(x, style)\n",
        "            else:\n",
        "                x, _, _ = x\n",
        "                x = x.to(self.device)\n",
        "                with torch.inference_mode():\n",
        "                    y_pred = self.model(x)\n",
        "\n",
        "            mask = self.loss_mask(y_pred, x)            \n",
        "            loss = self.masked_cross_entropy(y_pred[:, :-1], x[:, 1:], mask[:, :-1])\n",
        "            accuracy = self.masked_accuracy(y_pred, x)\n",
        "\n",
        "            average_loss += loss.item()\n",
        "            average_accuracy += accuracy.item()\n",
        "            \n",
        "        average_loss /= len(data_loader)\n",
        "        average_accuracy /= len(data_loader)   \n",
        "        \n",
        "        return np.exp(average_loss), average_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data loaders for the train and test sets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class ChordDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.all_genres = data[\"genre\"].apply(lambda x: x.split(\"|\")).explode().unique()\n",
        "        self.all_decades = data[\"decade\"].unique()\n",
        "        self.genre_to_idx = {genre: i for i, genre in enumerate(self.all_genres)}\n",
        "        self.decade_to_idx = {decade: i for i, decade in enumerate(self.all_decades)}\n",
        "\n",
        "    def pad(self, chords):\n",
        "        \"\"\"Pad the input tensor of shape [n] into shape [256] with zeros and special tokens\"\"\"\n",
        "        out = torch.zeros((256))\n",
        "        out[0] = VOCAB_SIZE - 2 # Start of sequence token\n",
        "        out[1 : 1 + len(chords)] = chords\n",
        "        out[1 + len(chords)] = VOCAB_SIZE - 1 # End of sequence token\n",
        "        return out\n",
        "\n",
        "    def multi_hot(self, genres, decade):\n",
        "        \"\"\"Convert a list of genres and a decade into a multi-hot vector\"\"\"\n",
        "        genre_style = torch.zeros((len(self.all_genres)))\n",
        "        genre_style[[self.genre_to_idx[genre] for genre in genres]] = 1\n",
        "        genre_style /= genre_style.sum() # Normalize as there can be multiple genres\n",
        "        \n",
        "        decade_style = torch.zeros((len(self.all_decades)))\n",
        "        decade_style[self.decade_to_idx[decade]] = 1\n",
        "        \n",
        "        return torch.cat([genre_style, decade_style])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.data.iloc[index]\n",
        "        x = row[\"chords\"]\n",
        "        x = self.pad(x).long()\n",
        "        \n",
        "        genres = self.multi_hot(row[\"genre\"].split(\"|\"), row[\"decade\"])\n",
        "        styles = row[\"style_s\"], row[\"style_m\"], row[\"style_l\"]\n",
        "        \n",
        "        return x, genres, styles\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "dataset = ChordDataset(data)\n",
        "\n",
        "train_size = np.rint(len(dataset) * 0.8).astype(int)\n",
        "train_data, test_data = random_split(dataset, [train_size, len(dataset) - train_size])\n",
        "\n",
        "# Define the dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size=128)\n",
        "test_loader = DataLoader(test_data, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>train_perplexity</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>test_perplexity</th>\n",
              "      <th>test_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>recurrent_net</td>\n",
              "      <td>4.927489</td>\n",
              "      <td>0.560048</td>\n",
              "      <td>4.850823</td>\n",
              "      <td>0.565912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>transformer_small</td>\n",
              "      <td>3.156535</td>\n",
              "      <td>0.687364</td>\n",
              "      <td>3.123427</td>\n",
              "      <td>0.690507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>transformer_medium</td>\n",
              "      <td>2.682259</td>\n",
              "      <td>0.737712</td>\n",
              "      <td>2.677365</td>\n",
              "      <td>0.739093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>transformer_large</td>\n",
              "      <td>2.505561</td>\n",
              "      <td>0.759765</td>\n",
              "      <td>2.513159</td>\n",
              "      <td>0.760409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>conditional_small</td>\n",
              "      <td>3.547666</td>\n",
              "      <td>0.645767</td>\n",
              "      <td>3.520874</td>\n",
              "      <td>0.648063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>conditional_medium</td>\n",
              "      <td>2.785376</td>\n",
              "      <td>0.727548</td>\n",
              "      <td>2.773981</td>\n",
              "      <td>0.729867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>conditional_large</td>\n",
              "      <td>2.551218</td>\n",
              "      <td>0.751437</td>\n",
              "      <td>2.561826</td>\n",
              "      <td>0.751403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>style_small</td>\n",
              "      <td>3.495391</td>\n",
              "      <td>0.622480</td>\n",
              "      <td>3.473176</td>\n",
              "      <td>0.625798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>style_medium</td>\n",
              "      <td>2.581267</td>\n",
              "      <td>0.726275</td>\n",
              "      <td>2.560228</td>\n",
              "      <td>0.728987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>style_large</td>\n",
              "      <td>2.252280</td>\n",
              "      <td>0.763176</td>\n",
              "      <td>2.263705</td>\n",
              "      <td>0.763126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                model  train_perplexity  train_accuracy  test_perplexity  \\\n",
              "0       recurrent_net          4.927489        0.560048         4.850823   \n",
              "1   transformer_small          3.156535        0.687364         3.123427   \n",
              "2  transformer_medium          2.682259        0.737712         2.677365   \n",
              "3   transformer_large          2.505561        0.759765         2.513159   \n",
              "4   conditional_small          3.547666        0.645767         3.520874   \n",
              "5  conditional_medium          2.785376        0.727548         2.773981   \n",
              "6   conditional_large          2.551218        0.751437         2.561826   \n",
              "7         style_small          3.495391        0.622480         3.473176   \n",
              "8        style_medium          2.581267        0.726275         2.560228   \n",
              "9         style_large          2.252280        0.763176         2.263705   \n",
              "\n",
              "   test_accuracy  \n",
              "0       0.565912  \n",
              "1       0.690507  \n",
              "2       0.739093  \n",
              "3       0.760409  \n",
              "4       0.648063  \n",
              "5       0.729867  \n",
              "6       0.751403  \n",
              "7       0.625798  \n",
              "8       0.728987  \n",
              "9       0.763126  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize all models\n",
        "recurrent_net = recurrent_network.Main().model\n",
        "\n",
        "# Initialize models with variants\n",
        "variants = [\"small\", \"medium\", \"large\"]\n",
        "transformer_nets = [transformer.Main(variant).model for variant in variants]\n",
        "conditional_nets = [conditional_transformer.Main(variant).model for variant in variants]\n",
        "style_nets = [style_transformer.Main(variant).model for variant in variants]\n",
        "\n",
        "# Convert all models to ONNX\n",
        "models = [recurrent_net] + transformer_nets + conditional_nets + style_nets\n",
        "model_names = [\"recurrent_net\"] + [f\"transformer_{v}\" for v in variants] + [f\"conditional_{v}\" for v in variants] + [f\"style_{v}\" for v in variants]\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "scores = []\n",
        "for model, name in zip(models, model_names):\n",
        "    trainer = Trainer(model, device)\n",
        "    \n",
        "    train_perplexity, train_accuracy = trainer.eval_step(train_loader, name)\n",
        "    test_perplexity, test_accuracy = trainer.eval_step(test_loader, name) \n",
        "\n",
        "    scores.append({\"model\": name, \"train_perplexity\": train_perplexity, \"train_accuracy\": train_accuracy, \"test_perplexity\": test_perplexity, \"test_accuracy\": test_accuracy})\n",
        "scores = pd.DataFrame(scores)\n",
        "scores"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "base"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
