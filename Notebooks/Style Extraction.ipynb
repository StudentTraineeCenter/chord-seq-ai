{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style-extraction using a Classification Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>decade</th>\n",
       "      <th>genre</th>\n",
       "      <th>ratings</th>\n",
       "      <th>stars</th>\n",
       "      <th>chords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/jeff-buck...</td>\n",
       "      <td>Hallelujah</td>\n",
       "      <td>Jeff Buckley</td>\n",
       "      <td>1990</td>\n",
       "      <td>Rock|Folk</td>\n",
       "      <td>51639.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[tensor(685), tensor(677), tensor(685), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/ed-sheera...</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>2010</td>\n",
       "      <td>Pop</td>\n",
       "      <td>44194.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[tensor(162), tensor(34), tensor(685), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/elvis-pre...</td>\n",
       "      <td>Cant Help Falling In Love</td>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>1960</td>\n",
       "      <td>Soundtrack|R&amp;B, Funk &amp; Soul</td>\n",
       "      <td>30059.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[tensor(685), tensor(162), tensor(677), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/eagles/ho...</td>\n",
       "      <td>Hotel California</td>\n",
       "      <td>Eagles</td>\n",
       "      <td>1970</td>\n",
       "      <td>Rock</td>\n",
       "      <td>28670.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[tensor(173), tensor(422), tensor(397), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/radiohead...</td>\n",
       "      <td>Creep</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>1990</td>\n",
       "      <td>Rock</td>\n",
       "      <td>28606.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[tensor(162), tensor(83), tensor(685), tensor(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://tabs.ultimate-guitar.com/tab/jeff-buck...   \n",
       "1  https://tabs.ultimate-guitar.com/tab/ed-sheera...   \n",
       "2  https://tabs.ultimate-guitar.com/tab/elvis-pre...   \n",
       "3  https://tabs.ultimate-guitar.com/tab/eagles/ho...   \n",
       "4  https://tabs.ultimate-guitar.com/tab/radiohead...   \n",
       "\n",
       "                       title         artist  decade  \\\n",
       "0                 Hallelujah   Jeff Buckley    1990   \n",
       "1                    Perfect     Ed Sheeran    2010   \n",
       "2  Cant Help Falling In Love  Elvis Presley    1960   \n",
       "3           Hotel California         Eagles    1970   \n",
       "4                      Creep      Radiohead    1990   \n",
       "\n",
       "                         genre  ratings  stars  \\\n",
       "0                    Rock|Folk  51639.0    5.0   \n",
       "1                          Pop  44194.0    5.0   \n",
       "2  Soundtrack|R&B, Funk & Soul  30059.0    5.0   \n",
       "3                         Rock  28670.0    5.0   \n",
       "4                         Rock  28606.0    5.0   \n",
       "\n",
       "                                              chords  \n",
       "0  [tensor(685), tensor(677), tensor(685), tensor...  \n",
       "1  [tensor(162), tensor(34), tensor(685), tensor(...  \n",
       "2  [tensor(685), tensor(162), tensor(677), tensor...  \n",
       "3  [tensor(173), tensor(422), tensor(397), tensor...  \n",
       "4  [tensor(162), tensor(83), tensor(685), tensor(...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/data_tokenized_pitch_class.csv')\n",
    "data[\"chords\"] = data[\"chords\"].apply(lambda x: torch.tensor(json.loads(x)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentation_map = torch.tensor(np.load('../Data/augmentation_map.npy', allow_pickle=True))\n",
    "\n",
    "with open(\"../Data/token_to_chord.json\", \"r\") as f:\n",
    "    token_to_chord = json.load(f)\n",
    "# Convert the dictionary keys to integers\n",
    "token_to_chord = {int(k): v for k, v in token_to_chord.items()}\n",
    "\n",
    "# Start and end of sequence tokens are not needed\n",
    "VOCAB_SIZE = len(token_to_chord)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.move_by = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def augment(self, chords, move_by):\n",
    "        \"\"\"Change the root note of the chords by a random amount\"\"\"\n",
    "        return augmentation_map[chords, move_by]\n",
    "        \n",
    "    def pad(self, chords):\n",
    "        \"\"\"Pad the input tensor of shape [n] into shape [256] with zeros\"\"\"\n",
    "        out = torch.zeros((256))\n",
    "        out[:len(chords)] = chords\n",
    "        return out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data.iloc[idx][\"chords\"]\n",
    "        x = self.augment(x, self.move_by)\n",
    "        return self.pad(x).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "dataset = ChordDataset(data)\n",
    "# We need the data to remain in the same order\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.multi_head_attention = nn.MultiheadAttention(\n",
    "            embed_dim=d_model, num_heads=n_heads, batch_first=True\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4), nn.ReLU(), nn.Linear(d_model * 4, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Multi-head attention\n",
    "        att_input = self.layer_norm1(x)\n",
    "        att_output = self.multi_head_attention(att_input, att_input, att_input, attn_mask=mask, need_weights=False)[0]\n",
    "        x = x + self.dropout1(att_output)\n",
    "\n",
    "        # Feed forward\n",
    "        ff_input = self.layer_norm2(x)\n",
    "        ff_output = self.feed_forward(ff_input)\n",
    "        x = x + self.dropout2(ff_output)\n",
    "        \n",
    "        return x \n",
    "\n",
    "\n",
    "class ClassificationTransformer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, n_layers, input_len, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, d_model)\n",
    "        self.transformer_blocks = nn.ModuleList([TransformerBlock(d_model, n_heads) for _ in range(n_layers)])\n",
    "        self.output = nn.Linear(d_model, output_dim)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.register_buffer('pe', torch.zeros(input_len, d_model))\n",
    "        self.pe = torch.zeros(input_len, d_model)\n",
    "        pos = torch.arange(0, input_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model)\n",
    "        )\n",
    "        self.pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        \n",
    "    def generate_square_subsequent_mask(self, size):\n",
    "        \"\"\"Generate a boolean mask to avoid attending to future tokens.\"\"\"\n",
    "        mask = torch.triu(torch.ones(size, size), diagonal=1).bool()\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.pe\n",
    "\n",
    "        # Generate mask\n",
    "        mask = self.generate_square_subsequent_mask(x.size(1)).to(x.device)\n",
    "\n",
    "        # Passing through all transformer blocks\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x, mask)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # For feature extraction, we don't need the output layer\n",
    "        # x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the style of the entire dataset with each of the classification models. The mean value across the transpositions will be used, as we do not want to insert any information about the key into the style. We will save these styles as a new column in our data DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with model size S...\n",
      "------------------\n",
      "Extracting style transposed by 0 semitones...\n",
      "Extracting style transposed by 1 semitones...\n",
      "Extracting style transposed by 2 semitones...\n",
      "Extracting style transposed by 3 semitones...\n",
      "Extracting style transposed by 4 semitones...\n",
      "Extracting style transposed by 5 semitones...\n",
      "Extracting style transposed by 6 semitones...\n",
      "Extracting style transposed by 7 semitones...\n",
      "Extracting style transposed by 8 semitones...\n",
      "Extracting style transposed by 9 semitones...\n",
      "Extracting style transposed by 10 semitones...\n",
      "Extracting style transposed by 11 semitones...\n",
      "Running with model size M...\n",
      "------------------\n",
      "Extracting style transposed by 0 semitones...\n",
      "Extracting style transposed by 1 semitones...\n",
      "Extracting style transposed by 2 semitones...\n",
      "Extracting style transposed by 3 semitones...\n",
      "Extracting style transposed by 4 semitones...\n",
      "Extracting style transposed by 5 semitones...\n",
      "Extracting style transposed by 6 semitones...\n",
      "Extracting style transposed by 7 semitones...\n",
      "Extracting style transposed by 8 semitones...\n",
      "Extracting style transposed by 9 semitones...\n",
      "Extracting style transposed by 10 semitones...\n",
      "Extracting style transposed by 11 semitones...\n",
      "Running with model size L...\n",
      "------------------\n",
      "Extracting style transposed by 0 semitones...\n",
      "Extracting style transposed by 1 semitones...\n",
      "Extracting style transposed by 2 semitones...\n",
      "Extracting style transposed by 3 semitones...\n",
      "Extracting style transposed by 4 semitones...\n",
      "Extracting style transposed by 5 semitones...\n",
      "Extracting style transposed by 6 semitones...\n",
      "Extracting style transposed by 7 semitones...\n",
      "Extracting style transposed by 8 semitones...\n",
      "Extracting style transposed by 9 semitones...\n",
      "Extracting style transposed by 10 semitones...\n",
      "Extracting style transposed by 11 semitones...\n"
     ]
    }
   ],
   "source": [
    "specs = [\n",
    "    {\"size\": \"S\", \"d_model\": 64, \"n_heads\": 8},\n",
    "    {\"size\": \"M\", \"d_model\": 80, \"n_heads\": 10},\n",
    "    {\"size\": \"L\", \"d_model\": 96, \"n_heads\": 12},\n",
    "]\n",
    "\n",
    "for spec in specs:\n",
    "    print(f\"Running with model size {spec['size']}...\\n------------------\")\n",
    "    classification_transformer = ClassificationTransformer(\n",
    "        d_model=spec[\"d_model\"],\n",
    "        n_heads=spec[\"n_heads\"],\n",
    "        n_layers=6,\n",
    "        input_len=256,\n",
    "        output_dim=28\n",
    "    ).to(device)\n",
    "\n",
    "    classification_transformer.load_state_dict(torch.load(f\"../Models/ClassificationTransformer{spec['size']}.pt\"))\n",
    "\n",
    "    all_styles = []\n",
    "    for transpose in range(12):\n",
    "        print(f\"Extracting style transposed by {transpose} semitones...\")\n",
    "        dataset.move_by = transpose\n",
    "\n",
    "        styles = []\n",
    "        for i, x in enumerate(dataloader):\n",
    "            classification_transformer.eval()\n",
    "            with torch.inference_mode():\n",
    "                styles.append(classification_transformer(x.to(device)))\n",
    "        styles = torch.cat(styles).cpu().detach().numpy()\n",
    "        all_styles.append(styles)\n",
    "    # Get the mean of all styles\n",
    "    data[f\"style_{spec['size'].lower()}\"] = np.stack(all_styles).mean(axis=0).tolist()\n",
    "    \n",
    "    # Convert to JSON\n",
    "    data[f\"style_{spec['size'].lower()}\"] = data[f\"style_{spec['size'].lower()}\"].apply(lambda x: json.dumps(x))\n",
    "\n",
    "# Convert to JSON\n",
    "data[\"chords\"] = data[\"chords\"].apply(lambda x: json.dumps(x.tolist()))\n",
    "\n",
    "# Save to CSV\n",
    "data.to_csv(\"../Data/data_styled.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
